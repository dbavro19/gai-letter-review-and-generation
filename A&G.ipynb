{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b3eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.162\n",
      "1.29.162\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "import boto3\n",
    "import json\n",
    "import botocore\n",
    "print(boto3.__version__)\n",
    "print(botocore.__version__)\n",
    "import os\n",
    "import sys\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import time\n",
    "from io import BytesIO\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "644803f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client('bedrock' , 'us-east-1', endpoint_url='https://bedrock.us-east-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c8cf63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenCount(text):\n",
    "    llm =OpenAI(temperature=0, openai_api_key=\"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\")\n",
    "    numtokens=llm.get_num_tokens(text)\n",
    "    print(\"Number of Tokens: \" + str(numtokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1385ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e3019e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed5531cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue=\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a117f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "research=\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f70cf992",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution=\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "65e4d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appeal and Greivance ##\n",
    "\n",
    "\n",
    "#Simple Prompt\n",
    "\n",
    "\n",
    "prompt_data = f\"\"\"\n",
    "###\n",
    "Please help me write a grievance (A&G) resolution letter for my X insurance company X.\n",
    "I'm supplying the member's complaint, the research we did, and a description of our resolution. Explain in a 5th grade reading level\n",
    "###\n",
    "Company: {company}\n",
    "###\n",
    "Product: {product}\n",
    "###\n",
    "Issue Description: {issue}\n",
    "###\n",
    "Resolution Research: {research}\n",
    "###\n",
    "Resolution Description: {resolution}\n",
    "###\n",
    "###\n",
    "\n",
    "Begin the task\n",
    "Human:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data,\n",
    "                 \"max_tokens_to_sample\":1000,\n",
    "                 \"temperature\":0,\n",
    "                 \"top_k\":250,\n",
    "                 \"top_p\":0.5,\n",
    "                 \"stop_sequences\":[]\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5915497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 539\n"
     ]
    }
   ],
   "source": [
    "getTokenCount(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a821d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run infernce on the LLM\n",
    "\n",
    "modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "llmOutput=response_body.get('completion')\n",
    "\n",
    "print(llmOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32eea207",
   "metadata": {},
   "outputs": [],
   "source": [
    "format=\"\"\"\n",
    "[Dear Member (do not assume a name unless one is provided)],\n",
    "\n",
    "[Introduction / Why we are reaching out]\n",
    "[Brief sumary of the issue]\n",
    "[Summary of the Resaerch and Resolution]\n",
    "[Any additonal infomration or actions being taken]\n",
    "[Conclusion and statement about X's commitment to customer serve and care]\n",
    "\n",
    "Sincerely,\n",
    "[X]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36e3bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appeal and Greivance ##\n",
    "\n",
    "\n",
    "#More Advanced Prompt\n",
    "\n",
    "\n",
    "prompt_data = f\"\"\"\n",
    "Human:\n",
    "###\n",
    "Please help me write a grievance (A&G) resolution letter for my x insurance company X.\n",
    "The following will be provided to be used as the basis for the generated resolution letter\n",
    "    Issue Description - a description of the issue/complaint the customer has filed\n",
    "    Resolution Research - The research we did\n",
    "    Resolution Description - The Description of the Resolution\n",
    "    Format - the format your response letter should follow\n",
    "\n",
    "The generated greivance resolution letter should be friendly, professional, consice, and written in a 5th grade reading level\n",
    "\n",
    "###\n",
    "Company: {company}\n",
    "###\n",
    "Product: {product}\n",
    "###\n",
    "Issue Description: {issue}\n",
    "###\n",
    "Resolution Research: {research}\n",
    "###\n",
    "Resolution Description: {resolution}\n",
    "###\n",
    "Format: {format}\n",
    "###\n",
    "\n",
    "Begin the task\n",
    "Assistant:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data,\n",
    "                 \"max_tokens_to_sample\":1000,\n",
    "                 \"temperature\":0,\n",
    "                 \"top_k\":250,\n",
    "                 \"top_p\":0.5,\n",
    "                 \"stop_sequences\":[]\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20b12323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 698\n"
     ]
    }
   ],
   "source": [
    "getTokenCount(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ee8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run infernce on the LLM\n",
    "\n",
    "modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "llmOutput=response_body.get('completion')\n",
    "\n",
    "print(llmOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9585610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###AI Test for reoslution quality###\n",
    "prompt_data = f\"\"\"\n",
    "Human:\n",
    "###\n",
    "Based on the information provided below, does the Resolution Description fully address ALL of the concerns or allegations from the member's complaint\n",
    "If not, what was not addressed?\n",
    "\n",
    "Be concise with your repsonse. If there are any items, direct or indirect that were not addresed please breifly ellaborate on them\n",
    "Format your response in human readable format, include bullet points where applicable\n",
    "###\n",
    "Company: {company}\n",
    "###\n",
    "Product: {product}\n",
    "###\n",
    "Issue Description: {issue}\n",
    "###\n",
    "Resolution Research: {research}\n",
    "###\n",
    "Resolution Description: {resolution}\n",
    "\n",
    "\n",
    "Begin the task\n",
    "Assistant:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data,\n",
    "                 \"max_tokens_to_sample\":1000,\n",
    "                 \"temperature\":0,\n",
    "                 \"top_k\":250,\n",
    "                 \"top_p\":0.5,\n",
    "                 \"stop_sequences\":[]\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c6b556e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 568\n"
     ]
    }
   ],
   "source": [
    "getTokenCount(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run infernce on the LLM\n",
    "\n",
    "modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "llmOutput=response_body.get('completion')\n",
    "\n",
    "print(llmOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f05fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
